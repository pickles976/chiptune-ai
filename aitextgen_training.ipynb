{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  aitextgen — Train a GPT-2 (or GPT Neo) Text-Generating Model w/ GPU\n",
        "\n",
        "by [Max Woolf](https://minimaxir.com), modified by [Seabass](https://github.com/pickles976)\n",
        "\n",
        "*Last updated: May 1sr, 2022 (aitextgen v0.5.2)*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Colaboratory** using `aitextgen`!\n",
        "\n",
        "For more about `aitextgen`, you can visit [this GitHub repository](https://github.com/minimaxir/aitextgen) or [read the documentation](https://docs.aitextgen.io/).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkpRgBCBS2_",
        "outputId": "26be9439-7e00-4579-81d1-58c2eab3d88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 92 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 419 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 430 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 440 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 450 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 460 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 471 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 481 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 491 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 501 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 512 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 522 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 532 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 542 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 552 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 563 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 572 kB 4.2 MB/s \n",
            "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/30/2022 16:33:38 — INFO — numexpr.utils — NumExpr defaulting to 4 threads.\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q aitextgen==0.4.0\n",
        "\n",
        "!pip install -q transformers>=4.0.0\n",
        "!pip install -q fire>=0.3.0\n",
        "!pip install -q pytorch-lightning>=1.0.8\n",
        "!pip install -q tokenizers>=1.0.0\n",
        "!pip install -q torch>=1.6.0\n",
        "!pip install -q aitextgen --no-deps\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses a Nvidia P4, an Nvidia T4, an Nvidia P100, or an Nvidia V100. For finetuning GPT-2 124M, any of these GPUs will be fine, but for text generation, a T4 or a P100 is ideal since they have more VRAM. **If you receive a T4 or a V100 GPU, you can enable `fp16=True` during training for faster/more memory efficient training.**\n",
        "\n",
        "You can verify which GPU is active by running the cell below. If you want to try for a different GPU, go to **Runtime -> Factory Reset Runtime**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUmTooTW3osf",
        "outputId": "ceaf24ff-a353-402b-c248-7ee5952df124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 30 16:33:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puq4iC6vUAHc",
        "outputId": "4348fdb3-c5e5-444b-bc1b-24fb424cbe13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "mount_gdrive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/w3wvHhR.png)\n",
        "\n",
        "Upload **any smaller text file** (for example, [a text file of Shakespeare plays](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "outputs": [],
      "source": [
        "# file_name = \"/content/lakh_dataset.txt\"\n",
        "file_name = \"/content/abc_8192.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is large (>10MB), it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM.\n",
        "\n",
        "Additionally, you may want to consider [compressing the dataset to a cache first](https://docs.aitextgen.io/dataset/) on your local computer, then uploading the resulting `dataset_cache.tar.gz` and setting the `file_name`in the previous cell to that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "outputs": [],
      "source": [
        "copy_file_from_gdrive(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQjDCTm6Fl2G"
      },
      "source": [
        "# Train From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3qcf_M_FRih"
      },
      "outputs": [],
      "source": [
        "from aitextgen.tokenizers import train_tokenizer\n",
        "train_tokenizer(file_name, vocab_size=8192,serialize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p51BzOzK6-U"
      },
      "outputs": [],
      "source": [
        "# If you want to load a partially-trained model\n",
        "ai = aitextgen(model_folder=\"/content/drive/MyDrive/NEO_NES_1000\",\n",
        "                tokenizer_file=\"aitextgen.tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGe3wxNkGHtO"
      },
      "outputs": [],
      "source": [
        "from aitextgen.TokenDataset import TokenDataset\n",
        "data = TokenDataset(file_name, block_size=2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ONLY USE ON FIRST RUN**\n",
        "building a new model and tokenizer"
      ],
      "metadata": {
        "id": "XDf-xijW2Qc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J877D7r9G6eR"
      },
      "outputs": [],
      "source": [
        "from aitextgen.utils import build_gpt2_config\n",
        "tokenizer_file = \"aitextgen.tokenizer.json\"\n",
        "config = build_gpt2_config(vocab_size=8192, max_length=2048, dropout=0.0, n_embd=768, n_layer=12, n_head=8) # 92M param\n",
        "ai = aitextgen(tokenizer_file=tokenizer_file, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fWM_tSNFsUh"
      },
      "outputs": [],
      "source": [
        "ai.train(file_name,\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         num_steps=1e5,\n",
        "         generate_every=5000,\n",
        "         save_every=5000,\n",
        "         save_gdrive=True,\n",
        "         learning_rate=1e-5,\n",
        "         fp16=False,\n",
        "         batch_size=1\n",
        "         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2 in aitextgen. It runs for `num_steps`, and a progress bar will appear to show training progress, current loss (the lower the better the model), and average loss (to give a sense on loss trajectory).\n",
        "\n",
        "The model will be saved every `save_every` steps in `trained_model` by default, and when training completes. If you mounted your Google Drive, the model will _also_ be saved there in a unique folder.\n",
        "\n",
        "The training might time out after 4ish hours; if you did not mount to Google Drive, make sure you end training and save the results so you don't lose them! (if this happens frequently, you may want to consider using [Colab Pro](https://colab.research.google.com/signup))\n",
        "\n",
        "Important parameters for `train()`:\n",
        "\n",
        "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
        "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
        "- **`num_steps`**: Number of steps to train the model for.\n",
        "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
        "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
        "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
        "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n",
        "\n",
        "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
        "\n",
        "- **`learning_rate`**: Learning rate of the model training.\n",
        "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. (if using `fp16`, you can increase the batch size more safely)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lFUXS2Ziagf"
      },
      "source": [
        "Load previously generated model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbfRSWwVjBKP",
        "outputId": "e87a0d65-1c3d-4fa8-b08a-30a7cbb76621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/30/2022 16:36:48 — INFO — aitextgen — Loading model from provided weights and config in //content/drive/MyDrive/NEO_LAKH_1092.\n",
            "04/30/2022 16:36:53 — INFO — aitextgen — GPT2 loaded with 92M parameters.\n",
            "04/30/2022 16:36:53 — INFO — aitextgen — Using a custom tokenizer.\n"
          ]
        }
      ],
      "source": [
        "from aitextgen.tokenizers import train_tokenizer\n",
        "file_name = \"/content/abc_8192.txt\"\n",
        "from_folder = \"/content/drive/MyDrive/NEO_LAKH_1092\"\n",
        "\n",
        "train_tokenizer(file_name, vocab_size=8192,serialize=True)\n",
        "ai = aitextgen(model_folder=from_folder,\n",
        "                tokenizer_file=\"aitextgen.tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ede3ae20eeb49ef93521383e20a3639",
            "eeb05c53f10d4a958cebf3a0e3bc41a9",
            "6a539af4e27c466385233edbe5d06a6c",
            "73c3142c29d04deca8629ba26640ae96",
            "d0d41fae7b4148d2afb486c854433909",
            "7fbf433d24ed4fe4809ae3a9de2f781f",
            "5ee78bf076234c3a81ead0d374909457",
            "df1f87af2fc14e71bc0cf03d05ebfadf",
            "c040af18da804920b0a09ecd4a29ba9a",
            "4cb7ff25b8394301a069faba1e7a04a7",
            "71705e7c41b04d88a45e0f2c0cdc15d8",
            "b4a9e0761853465e9eece16f5b249bb9",
            "01dfae3a66204c29aa6820b1ad35a41f",
            "1b4082bcef8d44c793cf2487405366e5",
            "63b941c26a594e5e83c4fa66b81c00f3",
            "5a1203a21c4842f8bfab861f7affd076",
            "d9c2522458d7431f9b4f3314346bb7e4",
            "6f2f2a8898844a4c90f0dd46f3739649",
            "eb5a969a8642460588395674d3ee72d2",
            "5ad5391fa2774e8ea1c7ceddd0b3dc4d",
            "e349e1f728e14933842d02c83ec8bb9e",
            "17507c2658e1474f825c1900188df5c5"
          ]
        },
        "outputId": "ce9e271b-ab32-4706-f391-d3b179ff49ba"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "04/30/2022 16:39:53 — INFO — aitextgen — Loading text from /content/abc_2048.txt with generation length of 2048.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ede3ae20eeb49ef93521383e20a3639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/91959 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "04/30/2022 16:39:53 — INFO — aitextgen.TokenDataset — Encoding 91,959 sets of tokens from /content/abc_2048.txt.\n",
            "04/30/2022 16:39:56 — WARNING — aitextgen — pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
            "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:172: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
            "  \"Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed\"\n",
            "04/30/2022 16:39:56 — INFO — pytorch_lightning.utilities.rank_zero — GPU available: True, used: True\n",
            "04/30/2022 16:39:56 — INFO — pytorch_lightning.utilities.rank_zero — TPU available: False, using: 0 TPU cores\n",
            "04/30/2022 16:39:56 — INFO — pytorch_lightning.utilities.rank_zero — IPU available: False, using: 0 IPUs\n",
            "04/30/2022 16:39:56 — INFO — pytorch_lightning.utilities.rank_zero — HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "  f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "04/30/2022 16:39:56 — INFO — pytorch_lightning.accelerators.gpu — LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4a9e0761853465e9eece16f5b249bb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50000.0 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:2265: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
            "  \"`trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "X:1\n",
            "T:Music21 Fragment\n",
            "C:Music21\n",
            "%%score 1 2 2 3 4\n",
            "L:1/16\n",
            "Q:1/4=120\n",
            "M:4/4\n",
            "I:linebreak $\n",
            "K:C\n",
            "V:1 treble nm=\"Violin\" snm=\"Vln\"\n",
            "V:2 treble nm=\"Viola\" snm=\"Vla\"\n",
            "V:3 treble nm=\"Celogue 2\" snm=\"Samp\"\n",
            "V:4 bass nm=\"Tuba\" snm=\"Tba\"\n",
            "V:1\n",
            " c z eg z g f z e z g z g z f z e z | c z dg z g f z e z g z g z f z e z | %2\n",
            " c z eg z g f z e z g z g z f z e z | c z dg z g f z e z g z g z f z e z | %4\n",
            " c z eg z g f z e z g z g z f z e z | c z dg z g f z e z g z g z f z e z | %6\n",
            " c z eg z g f z e z g z g z f z e z | c z dg z g f z\n",
            "==========\n",
            "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ":linebreak $\n",
            "K:F\n",
            "V:1 treble nm=\"Harpsichord\" snm=\"Hpschd\"\n",
            "V:2 bass \n",
            "V:1\n",
            " [DG]2[DG]2 [DG]2[DG]2 [DG]2[DG]2 [DG]2[CF]2 | [CG]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 [CG]2[CG]2 | %2\n",
            " [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 | [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 | %4\n",
            " [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 | [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 [CF]2[CG]2 | %6\n",
            " [CF]2[CG]2 [CF]2[CG]2 [CF\n",
            "==========\n",
            "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "X:1\n",
            "T:Music21 Fragment\n",
            "C:Music21\n",
            "%%score 1 2 3\n",
            "L:1/8\n",
            "Q:1/4=110\n",
            "M:4/4\n",
            "I:linebreak $\n",
            "K:none\n",
            "V:1 treble nm=\"Square Wave\" snm=\"Samp\"\n",
            "V:2 bass nm=\"Square Wave\" snm=\"Samp\"\n",
            "L:1/4\n",
            "V:3 bass nm=\"Triangle Wave\" snm=\"Tri\"\n",
            "V:1\n",
            " [C_E]3 [C_E]3 [A,^C]2 | [C_E]3 [CF]2 [D_B,]2 [DF] | [CF]3 [CF]2 [E^G]2 [E=G] | %3\n",
            " [_Ec]3 [C_E]3 [A,^C]2 | [C_E]3 [CF]2 [D_B,]2 [DF] | [CF]3 [CF]2 [E^G]2 [E=G] | %6\n",
            " [_Ec]3 [C_E]3 [A,^C]2 | [C_E]3 [CF]2 [D_\n",
            "==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "04/30/2022 19:31:51 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"
          ]
        }
      ],
      "source": [
        "file_name = \"/content/abc_2048.txt\"\n",
        "ai.train(file_name,\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         num_steps=0.5e5,\n",
        "         generate_every=5000,\n",
        "         save_every=5000,\n",
        "         save_gdrive=True,\n",
        "         learning_rate=1e-3,\n",
        "         fp16=False,\n",
        "         batch_size=1, \n",
        "         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "\n",
        "## Load a Trained Model\n",
        "\n",
        "If you already had a trained model from this notebook, running the next cell will copy the `pytorch_model.bin` and the `config.json`file from the specified folder in Google Drive into the Colaboratory VM. (If no `from_folder` is specified, it assumes the two files are located at the root level of your Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aitextgen.tokenizers import train_tokenizer\n",
        "file_name = \"/content/abc_8192.txt\"\n",
        "\n",
        "train_tokenizer(file_name, vocab_size=8192,serialize=True)"
      ],
      "metadata": {
        "id": "5lLyEoOIQEcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "outputs": [],
      "source": [
        "from_folder = \"/content/drive/MyDrive/NEO_LAKH_1092\"\n",
        "\n",
        "for file in [\"pytorch_model.bin\", \"config.json\"]:\n",
        "  if from_folder:\n",
        "    copy_file_from_gdrive(file, from_folder)\n",
        "  else:\n",
        "    copy_file_from_gdrive(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model + metadata necessary to generate text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxL77nvAMAX",
        "outputId": "b249b1c5-8a61-4f8b-cbf0-45abce166610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/30/2022 19:32:36 — INFO — aitextgen — Loading model from provided weights and config in /..\n",
            "04/30/2022 19:32:37 — INFO — aitextgen — GPT2 loaded with 92M parameters.\n",
            "04/30/2022 19:32:37 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"
          ]
        }
      ],
      "source": [
        "ai = aitextgen(model_folder=\".\",to_gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text.\n",
        "\n",
        "**If you just trained a model**, you'll get much faster training performance if you reload the model; the next cell will reload the model you just trained from the `trained_model` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSvHhTuHJc-Q",
        "outputId": "c457b951-e1b7-4377-d391-01f56f7fb561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/30/2022 19:32:42 — INFO — aitextgen — Loading model from provided weights and config in /..\n",
            "04/30/2022 19:32:43 — INFO — aitextgen — GPT2 loaded with 92M parameters.\n",
            "04/30/2022 19:32:43 — INFO — aitextgen — Using a custom tokenizer.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = \"/content/aitextgen.tokenizer.json\"\n",
        "ai = aitextgen(model_folder=\".\",tokenizer_file=tokenizer,to_gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cd0RGDbJiDp"
      },
      "source": [
        "`generate()` without any parameters generates a single text from the loaded model to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "8989c89e-3b01-40f1-9da6-15d3d87a4a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mX:1\n",
            "T:Music21 Fragment\n",
            "C:Music21\n",
            "%%score 1 2 3 4\n",
            "L:1/8\n",
            "Q:1/4=180\n",
            "M:4/4\n",
            "I:linebreak $\n",
            "K:none\n",
            "V:1 treble nm=\"Brass\" snm=\"Brs\"\n",
            "V:2 treble nm=\"Brass\" snm=\"Brs\"\n",
            "V:3 bass nm=\"Fretless Bass\" snm=\"Gtr\"\n",
            "V:4 bass nm=\"Percussion\" snm=\"Perc\"\n",
            "\u001b[0mV:1\n",
            " _ee z b ^c' z _ee z b ^c' z _e'f' | _e'_e'^c'=c' _b z =b z _e'f' _e' z ^g'b' | %2\n",
            " =c''2 _b' z =g z ^c' z =c' z ^g z c' z | _e' z b ^c' z =c' z _b^g g z ^f z =f z | %4\n",
            " _ee z b ^c' z _ee z b ^c' z _e'f' | _e'_e'^c'=c' _b z =b z _e'f' _e' z ^g'b' | %6\n",
            " =c''2 _b' z =g' z ^c' z =c' z ^g z c' z | _e' z b ^c' z =c' z _b^g g z ^f z =f z | %8\n",
            "V:2\n",
            " A,2 A,2 B, B,, | C,2 C2 ^C D | _E2 E2 _E =E | ^F2 F2 ^F =F | ^F2 F2 ^F =F | ^F2 F2 F ^F | %6\n",
            " ^G2 G2 ^F ^G | A2 A2 ^F ^G | A4 z4 | %10\n",
            "V:3\n",
            " ^G,, z G,, z G,, z G,, z G,, z G,, z G,, z | ^G,, z G,, z G,, z G,, z G,, z7 | %2\n",
            " A,, z A,, z A,, z A,, z A,, z A,, z A,, z | A,, z A,, z A,, z A,, z A,, z7 | %4\n",
            " A,, z A,, z A,, z A,, z A,, z A,, z A,, z | A,, z A,, z A,, z A,, z A,, z7 | %6\n",
            " A,2A,2 A,2 B, B,,4 z4 | E,, z E,, z E,, z E,, z F,, z F,, z F,, z | %8\n",
            "V:4\n",
            " z8 z4 z e z b z c' z | _e z b z e' z d' z _e z b z e' z D, z | %2\n",
            " _e z b z e' z _e' z B,/ z/ _e z b z e' z | _e z b z e' z =e' z _e z b z e' z =e' z | %4\n",
            " _e z b z e' z =e' z _e z b z e' z _e' z | _e z b z e' z =e' z _e z b z e' z =e' z | %6\n",
            " _e z b z e' z =e' z _e z b z e' z _e' z | _e z b z e' z =e' z _e z b z e' z =e' z | %8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt=\"\"\"X:1\n",
        "T:Music21 Fragment\n",
        "C:Music21\n",
        "%%score 1 2 3 4\n",
        "L:1/8\n",
        "Q:1/4=180\n",
        "M:4/4\n",
        "I:linebreak $\n",
        "K:none\n",
        "V:1 treble nm=\"Brass\" snm=\"Brs\"\n",
        "V:2 treble nm=\"Brass\" snm=\"Brs\"\n",
        "V:3 bass nm=\"Fretless Bass\" snm=\"Gtr\"\n",
        "V:4 bass nm=\"Percussion\" snm=\"Perc\"\n",
        "\"\"\"\n",
        "\n",
        "ai.generate(prompt=prompt,max_length=2048,temperature=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = ai.generate_one()`\n",
        "\n",
        "You can also pass in a `prompt` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `n`. You can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 50 for `batch_size` to avoid going OOM).\n",
        "\n",
        "Other optional-but-helpful parameters for `ai.generate()` and friends:\n",
        "\n",
        "*  **`min length`**: The minimum length of the generated text: if the text is shorter than this value after cleanup, aitextgen will generate another one.\n",
        "*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2 and 2048 with GPT Neo)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of texts to a file and sort out the samples locally on your computer. The next cell will generate `num_files` files, each with `n` texts and whatever other parameters you would pass to `generate()`. The files can then be downloaded from the Files sidebar!\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "outputs": [],
      "source": [
        "num_files = 5\n",
        "\n",
        "for _ in range(num_files):\n",
        "  ai.generate_to_file(n=1000,\n",
        "                     batch_size=50,\n",
        "                     prompt=prompt,\n",
        "                     max_length=256,\n",
        "                     temperature=1.0,\n",
        "                     top_p=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020-2021 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "aitextgen_training",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ede3ae20eeb49ef93521383e20a3639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeb05c53f10d4a958cebf3a0e3bc41a9",
              "IPY_MODEL_6a539af4e27c466385233edbe5d06a6c",
              "IPY_MODEL_73c3142c29d04deca8629ba26640ae96"
            ],
            "layout": "IPY_MODEL_d0d41fae7b4148d2afb486c854433909"
          }
        },
        "eeb05c53f10d4a958cebf3a0e3bc41a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fbf433d24ed4fe4809ae3a9de2f781f",
            "placeholder": "​",
            "style": "IPY_MODEL_5ee78bf076234c3a81ead0d374909457",
            "value": "100%"
          }
        },
        "6a539af4e27c466385233edbe5d06a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1f87af2fc14e71bc0cf03d05ebfadf",
            "max": 91959,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c040af18da804920b0a09ecd4a29ba9a",
            "value": 91959
          }
        },
        "73c3142c29d04deca8629ba26640ae96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb7ff25b8394301a069faba1e7a04a7",
            "placeholder": "​",
            "style": "IPY_MODEL_71705e7c41b04d88a45e0f2c0cdc15d8",
            "value": " 91959/91959 [00:03&lt;00:00, 28317.27it/s]"
          }
        },
        "d0d41fae7b4148d2afb486c854433909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "7fbf433d24ed4fe4809ae3a9de2f781f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee78bf076234c3a81ead0d374909457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1f87af2fc14e71bc0cf03d05ebfadf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c040af18da804920b0a09ecd4a29ba9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb7ff25b8394301a069faba1e7a04a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71705e7c41b04d88a45e0f2c0cdc15d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4a9e0761853465e9eece16f5b249bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01dfae3a66204c29aa6820b1ad35a41f",
              "IPY_MODEL_1b4082bcef8d44c793cf2487405366e5",
              "IPY_MODEL_63b941c26a594e5e83c4fa66b81c00f3"
            ],
            "layout": "IPY_MODEL_5a1203a21c4842f8bfab861f7affd076"
          }
        },
        "01dfae3a66204c29aa6820b1ad35a41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c2522458d7431f9b4f3314346bb7e4",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2f2a8898844a4c90f0dd46f3739649",
            "value": "Loss: 0.311 — Avg: 0.322 — GPU Mem: 7114 MB:  30%"
          }
        },
        "1b4082bcef8d44c793cf2487405366e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb5a969a8642460588395674d3ee72d2",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ad5391fa2774e8ea1c7ceddd0b3dc4d",
            "value": 15040
          }
        },
        "63b941c26a594e5e83c4fa66b81c00f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e349e1f728e14933842d02c83ec8bb9e",
            "placeholder": "​",
            "style": "IPY_MODEL_17507c2658e1474f825c1900188df5c5",
            "value": " 15040/50000.0 [2:51:44&lt;6:39:11,  1.46it/s]"
          }
        },
        "5a1203a21c4842f8bfab861f7affd076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d9c2522458d7431f9b4f3314346bb7e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2f2a8898844a4c90f0dd46f3739649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb5a969a8642460588395674d3ee72d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad5391fa2774e8ea1c7ceddd0b3dc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e349e1f728e14933842d02c83ec8bb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17507c2658e1474f825c1900188df5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}